{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://ncg-task.github.io/data/trial-data.zip\n",
        "!wget https://raw.githubusercontent.com/sarthakrastogi/NLP-Experiments/main/Passage%20Extraction/data.csv\n",
        "!wget https://raw.githubusercontent.com/sarthakrastogi/NLP-Experiments/main/Passage%20Extraction/text_preprocessing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbzLBX6t12Q0",
        "outputId": "4b55289c-ff3c-4590-d5c7-158ae007d3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-27 14:51:59--  https://ncg-task.github.io/data/trial-data.zip\n",
            "Resolving ncg-task.github.io (ncg-task.github.io)... 185.199.111.153, 185.199.110.153, 185.199.108.153, ...\n",
            "Connecting to ncg-task.github.io (ncg-task.github.io)|185.199.111.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30019272 (29M) [application/zip]\n",
            "Saving to: ‘trial-data.zip.1’\n",
            "\n",
            "trial-data.zip.1    100%[===================>]  28.63M  87.5MB/s    in 0.3s    \n",
            "\n",
            "2022-05-27 14:52:01 (87.5 MB/s) - ‘trial-data.zip.1’ saved [30019272/30019272]\n",
            "\n",
            "--2022-05-27 14:52:01--  https://raw.githubusercontent.com/sarthakrastogi/NLP-Experiments/main/Passage%20Extraction/data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 181994 (178K) [text/plain]\n",
            "Saving to: ‘data.csv.1’\n",
            "\n",
            "data.csv.1          100%[===================>] 177.73K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2022-05-27 14:52:01 (20.1 MB/s) - ‘data.csv.1’ saved [181994/181994]\n",
            "\n",
            "--2022-05-27 14:52:02--  https://raw.githubusercontent.com/sarthakrastogi/NLP-Experiments/main/Passage%20Extraction/text_preprocessing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1638 (1.6K) [text/plain]\n",
            "Saving to: ‘text_preprocessing.py.1’\n",
            "\n",
            "text_preprocessing. 100%[===================>]   1.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-27 14:52:02 (27.1 MB/s) - ‘text_preprocessing.py.1’ saved [1638/1638]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"trial-data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"trial-data\")"
      ],
      "metadata": {
        "id": "6uDlkcSK2E3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from text_preprocessing import *\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "#replace apply w progress_apply"
      ],
      "metadata": {
        "id": "Q3pnmhU63h_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T03:58:09.855624Z",
          "start_time": "2022-05-27T03:58:09.839300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ae0d8d64039d4b31b7e6729233a63a35",
            "45f3a0280f1e45e888588f3126c737d8",
            "4fcd0fa8b881452d98c2780b9e563cca",
            "ba56cdb2b0f246cdbb006fa14b0df0c8",
            "8714c835e9cc401794e6887a0e5d4367",
            "070fbb0cec0641ccaccf7fd490f2faa6",
            "17da8de2be1f417db23ebfdca6df159e",
            "38ea0c46b53b48038e3e5244614586fc",
            "d5afc893bfd14acdbf26036b5977bbd0",
            "5344f719298441f5bf8e8c68734e31c7",
            "f2d2d5b9d13942419be175198474bdbf"
          ]
        },
        "id": "0xckiyJM11M6",
        "outputId": "875d69c5-08c5-463f-b002-8269f49da8af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae0d8d64039d4b31b7e6729233a63a35"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "with open(\"files.txt\", \"w\") as f:\n",
        "    for path, currentDirectory, files in tqdm(os.walk(\"trial-data\")):\n",
        "        for file in files:\n",
        "            if file.endswith(\"Grobid-out.txt\"):\n",
        "                a = str(os.path.join(path, file))\n",
        "                #print(a)\n",
        "                f.write(a + '\\n')\n",
        "                #shutil.copy(os.path.abspath(file), 'trial-data/papers')\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:34.773492Z",
          "start_time": "2022-05-27T04:31:34.722809Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COBzVqa011NA",
        "outputId": "78d23f45-370d-4bd4-bd79-57bf13f0ecc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trial-data/relation-classification/0/1601.00770v3-Grobid-out.txt',\n",
              " 'trial-data/relation-classification/4/1809.10185v1-Grobid-out.txt',\n",
              " 'trial-data/relation-classification/8/1902.01030v2-Grobid-out.txt',\n",
              " 'trial-data/relation-classification/7/1901.08746v4-Grobid-out.txt',\n",
              " 'trial-data/relation-classification/2/1804.07847v3-Grobid-out.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "with open('files.txt') as file:\n",
        "    files = file.readlines()\n",
        "    files = [i.rstrip() for i in files]\n",
        "files[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:36.708305Z",
          "start_time": "2022-05-27T04:31:36.692356Z"
        },
        "id": "8R87Ng1J11NB"
      },
      "outputs": [],
      "source": [
        "def get_intro(a):\n",
        "    for i in a:\n",
        "        if i == 'Introduction\\n':\n",
        "            a = a[a.index(i) +1:]\n",
        "\n",
        "    intro = \"\"\n",
        "    for i in a:\n",
        "        intro += i.rstrip()\n",
        "        if len(i) <= 20:\n",
        "            break\n",
        "    \n",
        "    return intro\n",
        "\n",
        "def get_abstract(a):\n",
        "    for i in a:\n",
        "        if i == 'abstract\\n':\n",
        "            a = a[a.index(i) +1:]\n",
        "\n",
        "    abstract = \"\"\n",
        "    for i in a:\n",
        "        abstract += i.rstrip()\n",
        "        if len(i) <= 20:\n",
        "            break\n",
        "\n",
        "def get_title(a):\n",
        "    for i in a:\n",
        "        if i == 'title\\n':\n",
        "            title = a[a.index(i) +1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:36.939764Z",
          "start_time": "2022-05-27T04:31:36.857535Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_bIWmD4M11NC",
        "outputId": "696a24e1-ec1c-4c68-91b9-aee19825e657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nintros = []\\nabstracts = []\\ntitles = []\\n\\nfor i in range(len(files)):\\n    with open(files[i]) as file:\\n        paper_text = file.readlines()\\n        #print(paper_text)\\n    intro = get_intro(paper_text)\\n    title = get_title(paper_text)\\n    abstract = get_abstract(paper_text)\\n    \\n    intros.append(intro)\\n    titles.append(title)\\n    abstracts.append(abstract)\\n\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "'''\n",
        "intros = []\n",
        "abstracts = []\n",
        "titles = []\n",
        "\n",
        "for i in range(len(files)):\n",
        "    with open(files[i]) as file:\n",
        "        paper_text = file.readlines()\n",
        "        #print(paper_text)\n",
        "    intro = get_intro(paper_text)\n",
        "    title = get_title(paper_text)\n",
        "    abstract = get_abstract(paper_text)\n",
        "    \n",
        "    intros.append(intro)\n",
        "    titles.append(title)\n",
        "    abstracts.append(abstract)\n",
        "\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:37.281496Z",
          "start_time": "2022-05-27T04:31:37.253468Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "e_z75OP111ND",
        "outputId": "0a955b2d-d1a0-4eb9-8945-4365fa9dc56d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nintros2 = intros.copy()\\nfor intro in intros2:\\n    if intro == 'title':\\n        ind = intros.index(intro)\\n        intros.pop(ind)\\n        titles.pop(ind)\\n        abstracts.pop(ind)\\n        \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "'''\n",
        "intros2 = intros.copy()\n",
        "for intro in intros2:\n",
        "    if intro == 'title':\n",
        "        ind = intros.index(intro)\n",
        "        intros.pop(ind)\n",
        "        titles.pop(ind)\n",
        "        abstracts.pop(ind)\n",
        "        '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:41.824735Z",
          "start_time": "2022-05-27T04:31:41.799662Z"
        },
        "id": "HAzkiOtl11NH"
      },
      "outputs": [],
      "source": [
        "def preprocessing_pipeline(text):\n",
        "    text = remove_email(text)\n",
        "    text = remove_weblink(text)\n",
        "    text = remove_reference(text)\n",
        "    text = remove_ghost_char(text)\n",
        "    text = remove_brackets(text)\n",
        "    text = remove_extra_spaces(text)\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:31:42.396082Z",
          "start_time": "2022-05-27T04:31:42.233502Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PTwyKQy811NI",
        "outputId": "059d1842-e035-453c-c2e6-7aba831db2d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nintros = [preprocessing_pipeline(intro) for intro in intros]\\nabstracts = [preprocessing_pipeline(abstract) for abstract in abstracts]\\ntitles = [title.rstrip() for title in titles]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "\"\"\"\n",
        "intros = [preprocessing_pipeline(intro) for intro in intros]\n",
        "abstracts = [preprocessing_pipeline(abstract) for abstract in abstracts]\n",
        "titles = [title.rstrip() for title in titles]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(titles) == len(abstracts) == len(intros)"
      ],
      "metadata": {
        "id": "fihzBqzb4KVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "data = []\n",
        "\n",
        "for i in range(len(titles)):\n",
        "    data.append(\n",
        "        {'title' : titles[i],\n",
        "         'abstract' : abstracts[i],\n",
        "         'intro' : intros[i]\n",
        "       }\n",
        "    )\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.DataFrame(data)\n",
        "data.to_csv(\"data.csv\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JN4EVoMRci5D",
        "outputId": "80205059-5bed-49b7-e6d3-152cb28f236c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndata = []\\n\\nfor i in range(len(titles)):\\n    data.append(\\n        {\\'title\\' : titles[i],\\n         \\'abstract\\' : abstracts[i],\\n         \\'intro\\' : intros[i]\\n       }\\n    )\\n\\nimport pandas as pd\\ndata = pd.DataFrame(data)\\ndata.to_csv(\"data.csv\")\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-05-27T04:42:11.418155Z",
          "start_time": "2022-05-27T04:42:11.391118Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JnOImZHS11NI",
        "outputId": "dfab2013-2d06-4ff7-8ab5-58e136b96012"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Learning Phrase Representations using RNN Enco...   \n",
              "1          Neural Machine Translation in Linear Time   \n",
              "2                          Attention Is All You Need   \n",
              "3  Deep Recurrent Models with Fast-Forward Connec...   \n",
              "4  Unsupervised Neural Machine Translation with W...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  in this paper, we propose a novel neural netwo...   \n",
              "1  we present a novel neural network for processi...   \n",
              "2  the dominant sequence transduction models are ...   \n",
              "3  neural machine translation aims at solving mac...   \n",
              "4  unsupervised neural machine translation is a r...   \n",
              "\n",
              "                                               intro  \n",
              "0  deep neural networks have shown great success ...  \n",
              "1  in neural language modelling, a neural network...  \n",
              "2  recurrent neural networks, long short-term mem...  \n",
              "3  neural machine translation has attracted a lot...  \n",
              "4  neural machine translation, directly applying ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-545e96fc-cb38-45be-a185-3fa59d2ec059\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>intro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
              "      <td>in this paper, we propose a novel neural netwo...</td>\n",
              "      <td>deep neural networks have shown great success ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural Machine Translation in Linear Time</td>\n",
              "      <td>we present a novel neural network for processi...</td>\n",
              "      <td>in neural language modelling, a neural network...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attention Is All You Need</td>\n",
              "      <td>the dominant sequence transduction models are ...</td>\n",
              "      <td>recurrent neural networks, long short-term mem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Recurrent Models with Fast-Forward Connec...</td>\n",
              "      <td>neural machine translation aims at solving mac...</td>\n",
              "      <td>neural machine translation has attracted a lot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
              "      <td>unsupervised neural machine translation is a r...</td>\n",
              "      <td>neural machine translation, directly applying ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-545e96fc-cb38-45be-a185-3fa59d2ec059')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-545e96fc-cb38-45be-a185-3fa59d2ec059 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-545e96fc-cb38-45be-a185-3fa59d2ec059');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_intro(text):\n",
        "    return text.split(\". \")"
      ],
      "metadata": {
        "id": "QFkJA2a-eiHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['intro'] = data['intro'].apply(split_intro)"
      ],
      "metadata": {
        "id": "ieR1X3hEUlsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vvrvwpz0fVl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "HDf9zKcX5v8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "T2inwYdA5zN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emb(list_of_sens):\n",
        "    return sbert_model.encode(list_of_sens)"
      ],
      "metadata": {
        "id": "hY2VytNq5z0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['intro_emb'] = data['intro'].apply(get_emb) #3 mins"
      ],
      "metadata": {
        "id": "-z-smY7-frW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "#replace apply w progress_apply"
      ],
      "metadata": {
        "id": "qgtYr-zpgk4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Og9qf1uggj4M",
        "outputId": "ac47bfe0-359b-4399-af1b-1262182f867c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Learning Phrase Representations using RNN Enco...   \n",
              "1          Neural Machine Translation in Linear Time   \n",
              "2                          Attention Is All You Need   \n",
              "3  Deep Recurrent Models with Fast-Forward Connec...   \n",
              "4  Unsupervised Neural Machine Translation with W...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  in this paper, we propose a novel neural netwo...   \n",
              "1  we present a novel neural network for processi...   \n",
              "2  the dominant sequence transduction models are ...   \n",
              "3  neural machine translation aims at solving mac...   \n",
              "4  unsupervised neural machine translation is a r...   \n",
              "\n",
              "                                               intro  \\\n",
              "0  [deep neural networks have shown great success...   \n",
              "1  [in neural language modelling, a neural networ...   \n",
              "2  [recurrent neural networks, long short-term me...   \n",
              "3  [neural machine translation has attracted a lo...   \n",
              "4  [neural machine translation, directly applying...   \n",
              "\n",
              "                                           intro_emb  \n",
              "0  [[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...  \n",
              "1  [[0.108251475, -0.08667581, 0.55444056, 0.4823...  \n",
              "2  [[-0.5715559, 0.25395942, 0.8929722, 0.3264975...  \n",
              "3  [[-0.14071748, -0.097277634, 1.2162398, -0.146...  \n",
              "4  [[-0.29525474, 0.02305621, 0.42409566, 0.11174...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5f424da-637c-47cc-8487-a3f57059a1bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>intro</th>\n",
              "      <th>intro_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
              "      <td>in this paper, we propose a novel neural netwo...</td>\n",
              "      <td>[deep neural networks have shown great success...</td>\n",
              "      <td>[[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural Machine Translation in Linear Time</td>\n",
              "      <td>we present a novel neural network for processi...</td>\n",
              "      <td>[in neural language modelling, a neural networ...</td>\n",
              "      <td>[[0.108251475, -0.08667581, 0.55444056, 0.4823...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attention Is All You Need</td>\n",
              "      <td>the dominant sequence transduction models are ...</td>\n",
              "      <td>[recurrent neural networks, long short-term me...</td>\n",
              "      <td>[[-0.5715559, 0.25395942, 0.8929722, 0.3264975...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Recurrent Models with Fast-Forward Connec...</td>\n",
              "      <td>neural machine translation aims at solving mac...</td>\n",
              "      <td>[neural machine translation has attracted a lo...</td>\n",
              "      <td>[[-0.14071748, -0.097277634, 1.2162398, -0.146...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
              "      <td>unsupervised neural machine translation is a r...</td>\n",
              "      <td>[neural machine translation, directly applying...</td>\n",
              "      <td>[[-0.29525474, 0.02305621, 0.42409566, 0.11174...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5f424da-637c-47cc-8487-a3f57059a1bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5f424da-637c-47cc-8487-a3f57059a1bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5f424da-637c-47cc-8487-a3f57059a1bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"contributions of this paper\"\n",
        "global query_embedding\n",
        "query_embedding = sbert_model.encode([query]).tolist()[0]"
      ],
      "metadata": {
        "id": "9gd36rV36jGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "def cosine_sim(List1, List2):\n",
        "    return dot(List1, List2)/(norm(List1)*norm(List2))    "
      ],
      "metadata": {
        "id": "R-1LRWQw7Yo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim_compare(list_of_embs):\n",
        "    cos_sims = [round(cosine_sim(intro_emb, query_embedding), 4) for intro_emb in list_of_embs]\n",
        "    return cos_sims"
      ],
      "metadata": {
        "id": "GjNgG30FUOjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['intro_emb'][0] = data['intro_emb'][0].tolist()\n",
        "#data['intro_emb'][0]"
      ],
      "metadata": {
        "id": "7Edd0HBKjzMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cos_sims'] = data['intro_emb'].apply(cos_sim_compare)"
      ],
      "metadata": {
        "id": "p3EBu4nRhupX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "zRpg5DwciHyF",
        "outputId": "c26ea9fb-a623-4c7f-9361-e80ae4597f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Learning Phrase Representations using RNN Enco...   \n",
              "1          Neural Machine Translation in Linear Time   \n",
              "2                          Attention Is All You Need   \n",
              "3  Deep Recurrent Models with Fast-Forward Connec...   \n",
              "4  Unsupervised Neural Machine Translation with W...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  in this paper, we propose a novel neural netwo...   \n",
              "1  we present a novel neural network for processi...   \n",
              "2  the dominant sequence transduction models are ...   \n",
              "3  neural machine translation aims at solving mac...   \n",
              "4  unsupervised neural machine translation is a r...   \n",
              "\n",
              "                                               intro  \\\n",
              "0  [deep neural networks have shown great success...   \n",
              "1  [in neural language modelling, a neural networ...   \n",
              "2  [recurrent neural networks, long short-term me...   \n",
              "3  [neural machine translation has attracted a lo...   \n",
              "4  [neural machine translation, directly applying...   \n",
              "\n",
              "                                           intro_emb  \\\n",
              "0  [[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...   \n",
              "1  [[0.108251475, -0.08667581, 0.55444056, 0.4823...   \n",
              "2  [[-0.5715559, 0.25395942, 0.8929722, 0.3264975...   \n",
              "3  [[-0.14071748, -0.097277634, 1.2162398, -0.146...   \n",
              "4  [[-0.29525474, 0.02305621, 0.42409566, 0.11174...   \n",
              "\n",
              "                                            cos_sims  \n",
              "0  [0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...  \n",
              "1  [0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...  \n",
              "2  [0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...  \n",
              "3  [0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...  \n",
              "4  [0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af5b8cd8-7d44-46f6-9270-934a0285f4fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>intro</th>\n",
              "      <th>intro_emb</th>\n",
              "      <th>cos_sims</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
              "      <td>in this paper, we propose a novel neural netwo...</td>\n",
              "      <td>[deep neural networks have shown great success...</td>\n",
              "      <td>[[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...</td>\n",
              "      <td>[0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural Machine Translation in Linear Time</td>\n",
              "      <td>we present a novel neural network for processi...</td>\n",
              "      <td>[in neural language modelling, a neural networ...</td>\n",
              "      <td>[[0.108251475, -0.08667581, 0.55444056, 0.4823...</td>\n",
              "      <td>[0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attention Is All You Need</td>\n",
              "      <td>the dominant sequence transduction models are ...</td>\n",
              "      <td>[recurrent neural networks, long short-term me...</td>\n",
              "      <td>[[-0.5715559, 0.25395942, 0.8929722, 0.3264975...</td>\n",
              "      <td>[0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Recurrent Models with Fast-Forward Connec...</td>\n",
              "      <td>neural machine translation aims at solving mac...</td>\n",
              "      <td>[neural machine translation has attracted a lo...</td>\n",
              "      <td>[[-0.14071748, -0.097277634, 1.2162398, -0.146...</td>\n",
              "      <td>[0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
              "      <td>unsupervised neural machine translation is a r...</td>\n",
              "      <td>[neural machine translation, directly applying...</td>\n",
              "      <td>[[-0.29525474, 0.02305621, 0.42409566, 0.11174...</td>\n",
              "      <td>[0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5b8cd8-7d44-46f6-9270-934a0285f4fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af5b8cd8-7d44-46f6-9270-934a0285f4fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af5b8cd8-7d44-46f6-9270-934a0285f4fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_sims_indices(a):\n",
        "    return  np.argsort(a)[-5:].tolist()"
      ],
      "metadata": {
        "id": "x-MLC7Ivneta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['max_indices'] = data['intro'].apply(max_sims_indices)"
      ],
      "metadata": {
        "id": "jMLWQcVTm5aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['contribution_sentences'] = data.apply(lambda x: list(map(x['intro'].__getitem__, x['max_indices'])), axis=1)"
      ],
      "metadata": {
        "id": "l8wY4jFAq5rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_passage(l):\n",
        "    return \"\".join(l)\n",
        "data['contribution'] = data['contribution_sentences'].apply(list_to_passage)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "H5CQGDwaq57D",
        "outputId": "d8c08daa-8b28-461a-c558-bfdabfba81fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Learning Phrase Representations using RNN Enco...   \n",
              "1          Neural Machine Translation in Linear Time   \n",
              "2                          Attention Is All You Need   \n",
              "3  Deep Recurrent Models with Fast-Forward Connec...   \n",
              "4  Unsupervised Neural Machine Translation with W...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  in this paper, we propose a novel neural netwo...   \n",
              "1  we present a novel neural network for processi...   \n",
              "2  the dominant sequence transduction models are ...   \n",
              "3  neural machine translation aims at solving mac...   \n",
              "4  unsupervised neural machine translation is a r...   \n",
              "\n",
              "                                               intro  \\\n",
              "0  [deep neural networks have shown great success...   \n",
              "1  [in neural language modelling, a neural networ...   \n",
              "2  [recurrent neural networks, long short-term me...   \n",
              "3  [neural machine translation has attracted a lo...   \n",
              "4  [neural machine translation, directly applying...   \n",
              "\n",
              "                                           intro_emb  \\\n",
              "0  [[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...   \n",
              "1  [[0.108251475, -0.08667581, 0.55444056, 0.4823...   \n",
              "2  [[-0.5715559, 0.25395942, 0.8929722, 0.3264975...   \n",
              "3  [[-0.14071748, -0.097277634, 1.2162398, -0.146...   \n",
              "4  [[-0.29525474, 0.02305621, 0.42409566, 0.11174...   \n",
              "\n",
              "                                            cos_sims           max_indices  \\\n",
              "0  [0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...     [6, 13, 8, 2, 10]   \n",
              "1  [0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...  [13, 14, 24, 21, 22]   \n",
              "2  [0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...       [4, 0, 5, 7, 3]   \n",
              "3  [0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...   [16, 1, 10, 22, 18]   \n",
              "4  [0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...  [17, 24, 27, 23, 11]   \n",
              "\n",
              "                              contribution_sentences  \\\n",
              "0  [the proposed neural network architecture, whi...   \n",
              "1  [the second mechanism is the dynamic unfolding...   \n",
              "2  [recent work has achieved significant improvem...   \n",
              "3  [this topology can be used for both the encode...   \n",
              "4  [to map the latent representations from differ...   \n",
              "\n",
              "                                        contribution  \n",
              "0  the proposed neural network architecture, whic...  \n",
              "1  the second mechanism is the dynamic unfolding ...  \n",
              "2  recent work has achieved significant improveme...  \n",
              "3  this topology can be used for both the encoder...  \n",
              "4  to map the latent representations from differe...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ee4a3d3-5c18-498c-8a59-fadc70924ae1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>intro</th>\n",
              "      <th>intro_emb</th>\n",
              "      <th>cos_sims</th>\n",
              "      <th>max_indices</th>\n",
              "      <th>contribution_sentences</th>\n",
              "      <th>contribution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
              "      <td>in this paper, we propose a novel neural netwo...</td>\n",
              "      <td>[deep neural networks have shown great success...</td>\n",
              "      <td>[[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...</td>\n",
              "      <td>[0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...</td>\n",
              "      <td>[6, 13, 8, 2, 10]</td>\n",
              "      <td>[the proposed neural network architecture, whi...</td>\n",
              "      <td>the proposed neural network architecture, whic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural Machine Translation in Linear Time</td>\n",
              "      <td>we present a novel neural network for processi...</td>\n",
              "      <td>[in neural language modelling, a neural networ...</td>\n",
              "      <td>[[0.108251475, -0.08667581, 0.55444056, 0.4823...</td>\n",
              "      <td>[0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...</td>\n",
              "      <td>[13, 14, 24, 21, 22]</td>\n",
              "      <td>[the second mechanism is the dynamic unfolding...</td>\n",
              "      <td>the second mechanism is the dynamic unfolding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attention Is All You Need</td>\n",
              "      <td>the dominant sequence transduction models are ...</td>\n",
              "      <td>[recurrent neural networks, long short-term me...</td>\n",
              "      <td>[[-0.5715559, 0.25395942, 0.8929722, 0.3264975...</td>\n",
              "      <td>[0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...</td>\n",
              "      <td>[4, 0, 5, 7, 3]</td>\n",
              "      <td>[recent work has achieved significant improvem...</td>\n",
              "      <td>recent work has achieved significant improveme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Recurrent Models with Fast-Forward Connec...</td>\n",
              "      <td>neural machine translation aims at solving mac...</td>\n",
              "      <td>[neural machine translation has attracted a lo...</td>\n",
              "      <td>[[-0.14071748, -0.097277634, 1.2162398, -0.146...</td>\n",
              "      <td>[0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...</td>\n",
              "      <td>[16, 1, 10, 22, 18]</td>\n",
              "      <td>[this topology can be used for both the encode...</td>\n",
              "      <td>this topology can be used for both the encoder...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
              "      <td>unsupervised neural machine translation is a r...</td>\n",
              "      <td>[neural machine translation, directly applying...</td>\n",
              "      <td>[[-0.29525474, 0.02305621, 0.42409566, 0.11174...</td>\n",
              "      <td>[0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...</td>\n",
              "      <td>[17, 24, 27, 23, 11]</td>\n",
              "      <td>[to map the latent representations from differ...</td>\n",
              "      <td>to map the latent representations from differe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee4a3d3-5c18-498c-8a59-fadc70924ae1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ee4a3d3-5c18-498c-8a59-fadc70924ae1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ee4a3d3-5c18-498c-8a59-fadc70924ae1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def load_summarizer():\n",
        "    model = pipeline(\"summarization\", device=0)\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate_chunks(inp_str):\n",
        "    max_chunk = 500\n",
        "    inp_str = inp_str.replace('.', '.<eos>')\n",
        "    inp_str = inp_str.replace('?', '?<eos>')\n",
        "    inp_str = inp_str.replace('!', '!<eos>')\n",
        "    \n",
        "    sentences = inp_str.split('<eos>')\n",
        "    current_chunk = 0 \n",
        "    chunks = []\n",
        "    for sentence in sentences:\n",
        "        if len(chunks) == current_chunk + 1: \n",
        "            if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
        "                chunks[current_chunk].extend(sentence.split(' '))\n",
        "            else:\n",
        "                current_chunk += 1\n",
        "                chunks.append(sentence.split(' '))\n",
        "        else:\n",
        "            chunks.append(sentence.split(' '))\n",
        "\n",
        "    for chunk_id in range(len(chunks)):\n",
        "        chunks[chunk_id] = ' '.join(chunks[chunk_id])\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def summarise(text):\n",
        "\n",
        "    summarizer = load_summarizer()\n",
        "    chunks = generate_chunks(text)\n",
        "    res = summarizer(chunks,\n",
        "                            max_length=300, \n",
        "                            min_length=100, \n",
        "                            do_sample=False)\n",
        "    text = ' '.join([summ['summary_text'] for summ in res])\n",
        "    return text"
      ],
      "metadata": {
        "id": "DgmazxhWrtHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarise(data['contribution'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aYgZfwpjyKtI",
        "outputId": "a122f709-54fc-4008-e013-9ea0a4120dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The proposed neural network architecture consists of two recurrent neural networks that act as an encoder and a decoder pair . The rnn encoder-decoder is better at capturing linguistic regularities in the phrase table . The network is trained jointly to maximize the conditional probability of the target sequence given a source sequencencenchere is modeled language modeling, paraphrase detection and word embedding extraction . We train the model to learn the translation probability of an english phrase to a corresponding french phrase .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['contribution'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "6mrRvZ4S00S9",
        "outputId": "2058ba37-7c56-46a4-e08d-bfc9767c1509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the proposed neural network architecture, which we will refer to as an rnn encoder-decoder, consists of two recurrent neural networks that act as an encoder and a decoder pairthe qualitative analysis shows that the rnn encoder-decoder is better at capturing the linguistic regularities in the phrase table, indirectly explaining the quantitative improvements in the overall translation performancethe two networks are trained jointly to maximize the conditional probability of the target sequence given a source sequencethese include, but are not limited to, language modeling, paraphrase detection and word embedding extractionwe train the model to learn the translation probability of an english phrase to a corresponding french phrase'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['contribution_summary'] = data['contribution'].progress_apply(summarise) #8 mins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "94001c34152040af88ccd7cbcdf62e5e",
            "7b790149cf8248c1ab6d487697ef7fbc",
            "1e17656eb11c4884a1faf18a7ddb9e18",
            "bc9e561813be44ce8e202ee5238b3877",
            "18aed4e0406644db9f605fa9f8141c4e",
            "7192c1b6f78e42abaad7190d67625ec2",
            "32155cd7b9c24134aa847beeafc21ccc",
            "e9696495e76144e8b94fcbda0ab77dc6",
            "ac4027786a274edcba0fdc9d0070483f",
            "31a47878c80f4639a7dccd818865bca4",
            "af69c17f03d240e99f8e8b69f711d708"
          ]
        },
        "id": "2dbywznh0_my",
        "outputId": "30ba1e40-36dc-4944-c82a-2dcbd05528c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/42 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94001c34152040af88ccd7cbcdf62e5e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m_bNGP2U1Nom",
        "outputId": "8012052b-07b1-44cb-cee9-785f16d4b805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                title  \\\n",
              "0   Learning Phrase Representations using RNN Enco...   \n",
              "1           Neural Machine Translation in Linear Time   \n",
              "2                           Attention Is All You Need   \n",
              "3   Deep Recurrent Models with Fast-Forward Connec...   \n",
              "4   Unsupervised Neural Machine Translation with W...   \n",
              "5    Tilde's Machine Translation Systems for WMT 2018   \n",
              "6       FRAGE: Frequency-Agnostic Word Representation   \n",
              "7   0,000+ Times Accelerated Robust Subset Selecti...   \n",
              "8   Neural Architectures for Named Entity Recognition   \n",
              "9   Fast and Accurate Entity Recognition with Iter...   \n",
              "10  Semi-supervised sequence tagging with bidirect...   \n",
              "11           Deep contextualized word representations   \n",
              "12        Sentence-State LSTM for Text Representation   \n",
              "13  Robust Lexical Features for Improved Neural Ne...   \n",
              "14  A Neural Transition-based Model for Nested Men...   \n",
              "15  BERT: Pre-training of Deep Bidirectional Trans...   \n",
              "16  Data and text mining BioBERT: a pre-trained bi...   \n",
              "17  Open Question Answering with Weakly Supervised...   \n",
              "18  Convolutional Neural Network Architectures for...   \n",
              "19  Large-scale Simple Question Answering with Mem...   \n",
              "20  A Parallel-Hierarchical Model for Machine Comp...   \n",
              "21  Iterative Alternating Neural Attention for Mac...   \n",
              "22  End-to-End Relation Extraction using LSTMs on ...   \n",
              "23  Joint Extraction of Entities and Relations Bas...   \n",
              "24  Joint entity recognition and relation extracti...   \n",
              "25  Adversarial training for multi-context joint e...   \n",
              "26  Graph Convolution over Pruned Dependency Trees...   \n",
              "27  End-to-end neural relation extraction using de...   \n",
              "28  Semantic Relation Classification via Bidirecti...   \n",
              "29  Data and text mining BioBERT: a pre-trained bi...   \n",
              "30  Extracting Multiple-Relations in One-Pass with...   \n",
              "31  SCIBERT: A Pretrained Language Model for Scien...   \n",
              "32  Character-level Convolutional Networks for Tex...   \n",
              "33  Supervised and Semi-Supervised Text Categoriza...   \n",
              "34    Bag of Tricks for Efficient Text Classification   \n",
              "35  On the Role of Text Preprocessing in Neural Ne...   \n",
              "36  Learning Context-Sensitive Convolutional Filte...   \n",
              "37  Universal Language Model Fine-tuning for Text ...   \n",
              "38                         Universal Sentence Encoder   \n",
              "39  Investigating Capsule Networks with Dynamic Ro...   \n",
              "40  Baseline Needs More Love: On Simple Word-Embed...   \n",
              "41  Translations as Additional Contexts for Senten...   \n",
              "\n",
              "                                             abstract  \\\n",
              "0   in this paper, we propose a novel neural netwo...   \n",
              "1   we present a novel neural network for processi...   \n",
              "2   the dominant sequence transduction models are ...   \n",
              "3   neural machine translation aims at solving mac...   \n",
              "4   unsupervised neural machine translation is a r...   \n",
              "5   the paper describes the development process of...   \n",
              "6   continuous word representation is a basic buil...   \n",
              "7   subset selection from massive data with noised...   \n",
              "8   state-of-the-art named entity recognition syst...   \n",
              "9   today when many practitioners run basic nlp on...   \n",
              "10  pre-trained word embeddings learned from unlab...   \n",
              "11  we introduce anew type of deep contextualized ...   \n",
              "12  bi-directional lstms area powerful tool for te...   \n",
              "13  neural network approaches to named-entity reco...   \n",
              "14  it is common that entity mentions can contain ...   \n",
              "15  we introduce anew language representation mode...   \n",
              "16  motivation: biomedical text mining is becoming...   \n",
              "17  building computers able to answer questions on...   \n",
              "18  semantic matching is of central importance to ...   \n",
              "19  training large-scale question answering system...   \n",
              "20  understanding unstructured text is a major goa...   \n",
              "21  we propose a novel neural attention architectu...   \n",
              "22  we present a novel end-to-end neural model to ...   \n",
              "23  joint extraction of entities and relations is ...   \n",
              "24  state-of-the-art models for joint entity recog...   \n",
              "25  adversarial training is a regularization metho...   \n",
              "26  dependency trees help relation extraction mode...   \n",
              "27  we propose a neural network model for joint ex...   \n",
              "28  classifying semantic relations between entity ...   \n",
              "29  motivation: biomedical text mining is becoming...   \n",
              "30  the state-of-the-art solutions for extracting ...   \n",
              "31  obtaining large-scale annotated data for nlp t...   \n",
              "32  this article offers an empirical exploration o...   \n",
              "33  one-hot cnn has been shown to be effective for...   \n",
              "34  this paper explores a simple and efficient bas...   \n",
              "35  text preprocessing is often the first step in ...   \n",
              "36  convolutional neural networks have recently em...   \n",
              "37  inductive transfer learning has greatly impact...   \n",
              "38  we present models for encoding sentences into ...   \n",
              "39  in this study, we explore capsule networks wit...   \n",
              "40  many deep learning architectures have been pro...   \n",
              "41  in sentence classification tasks, additional c...   \n",
              "\n",
              "                                                intro  \\\n",
              "0   [deep neural networks have shown great success...   \n",
              "1   [in neural language modelling, a neural networ...   \n",
              "2   [recurrent neural networks, long short-term me...   \n",
              "3   [neural machine translation has attracted a lo...   \n",
              "4   [neural machine translation, directly applying...   \n",
              "5   [neural machine translation is a rapidly chang...   \n",
              "6   [word embeddings, which are distributed and co...   \n",
              "7   [due to the explosive growth of data, subset s...   \n",
              "8   [named entity recognition is a challenging lea...   \n",
              "9   [in order to democratize large-scale nlp and i...   \n",
              "10  [due to their simplicity and efficacy, pre-tra...   \n",
              "11  [pre-trained word representations area key com...   \n",
              "12  [neural models have become the dominant approa...   \n",
              "13  [named-entity recognition is the task of ident...   \n",
              "14  [there has been an increasing interest in name...   \n",
              "15  [language model pre-training has been shown to...   \n",
              "16  [the volume of biomedical literature continues...   \n",
              "17  [this paper addresses the challenging problem ...   \n",
              "18  [matching two potentially heterogenous languag...   \n",
              "19  [open-domain question answering systems aim at...   \n",
              "20  [humans learn in a variety of ways-by communic...   \n",
              "21  [recently, the idea of training machine compre...   \n",
              "22  [extracting semantic relations between entitie...   \n",
              "23  [joint extraction of entities and relations is...   \n",
              "24  [the goal of the entity recognition and relati...   \n",
              "25  [many neural network methods have recently bee...   \n",
              "26  [relation extraction involves discerning wheth...   \n",
              "27  [extracting entities and their semantic relati...   \n",
              "28  [classifying semantic relations between entity...   \n",
              "29  [the volume of biomedical literature continues...   \n",
              "30  [relation extraction aims to find the semantic...   \n",
              "31  [the exponential increase in the volume of sci...   \n",
              "32  [text classification is a classic topic for na...   \n",
              "33  [text categorization is the task of assigning ...   \n",
              "34  [text classification is an important task in n...   \n",
              "35  [words are often considered as the basic const...   \n",
              "36  [in the last few years, convolutional neural n...   \n",
              "37  [inductive transfer learning has had a large i...   \n",
              "38  [limited amounts of training data are availabl...   \n",
              "39  [modeling articles or sentences computationall...   \n",
              "40  [word embeddings, learned from massive unstruc...   \n",
              "41  [one of the primary tasks in natural language ...   \n",
              "\n",
              "                                            intro_emb  \\\n",
              "0   [[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...   \n",
              "1   [[0.108251475, -0.08667581, 0.55444056, 0.4823...   \n",
              "2   [[-0.5715559, 0.25395942, 0.8929722, 0.3264975...   \n",
              "3   [[-0.14071748, -0.097277634, 1.2162398, -0.146...   \n",
              "4   [[-0.29525474, 0.02305621, 0.42409566, 0.11174...   \n",
              "5   [[-0.13414781, -0.2282693, 1.2828408, -0.17528...   \n",
              "6   [[-0.45439413, 0.37135765, 0.23966111, 0.35358...   \n",
              "7   [[-0.1329963, -0.22868472, 1.4659978, 0.183145...   \n",
              "8   [[-0.25237015, 0.22781274, 1.0218633, 0.704382...   \n",
              "9   [[-0.5760207, 0.504138, 0.29743108, 0.48354793...   \n",
              "10  [[-0.29862925, 0.1646118, 0.4163921, 0.2801728...   \n",
              "11  [[0.016203806, 0.21462773, 1.0062764, 0.434290...   \n",
              "12  [[-0.17486975, -0.41252342, 1.5462731, -0.2084...   \n",
              "13  [[-0.027427938, 0.7781579, 0.14958529, 0.33615...   \n",
              "14  [[0.080848336, 0.33237612, 1.3055669, 0.028802...   \n",
              "15  [[-0.28008252, -0.18042819, 0.6790624, -0.0071...   \n",
              "16  [[0.7987201, -0.15887147, 1.7703805, -0.278009...   \n",
              "17  [[-0.25996676, 0.6575827, 0.79837936, 0.637119...   \n",
              "18  [[-0.2356596, 0.29604667, 0.17470802, 0.207097...   \n",
              "19  [[-0.15790537, 0.49199095, 0.26630324, 0.39525...   \n",
              "20  [[-0.2681135, 0.51422447, 1.1493917, 0.6535939...   \n",
              "21  [[-0.61436677, -0.12127957, 1.5850064, 0.62324...   \n",
              "22  [[-0.6867979, 0.5289896, 1.0703982, 0.15692762...   \n",
              "23  [[-0.415223, 1.097821, 0.59927785, 0.38558003,...   \n",
              "24  [[-0.41306046, 1.675093, 0.2402155, 0.35095933...   \n",
              "25  [[-0.10987496, 0.09705745, 0.6809278, 0.286776...   \n",
              "26  [[-0.17918232, 0.25339183, 0.27279842, 0.33350...   \n",
              "27  [[-0.33283246, 0.36472216, 0.9390662, 0.642776...   \n",
              "28  [[-0.608256, 0.55602336, 0.6793852, 0.5575708,...   \n",
              "29  [[0.7987201, -0.15887147, 1.7703805, -0.278009...   \n",
              "30  [[-0.21298881, 0.6873293, 0.68065774, 0.259553...   \n",
              "31  [[-0.35356942, -0.083761044, 0.94317627, -0.08...   \n",
              "32  [[-0.26952654, 0.57736915, 0.43923575, 0.63989...   \n",
              "33  [[-0.333069, 0.50793964, 0.14468037, 0.3841369...   \n",
              "34  [[-0.41828865, 0.1735431, 1.5629678, 0.0858151...   \n",
              "35  [[-0.54336274, 1.0743241, -0.1217025, -0.10105...   \n",
              "36  [[-0.33753395, 0.052655704, 0.9955412, -0.0359...   \n",
              "37  [[-0.13765128, -0.15379387, 0.95918, 0.3047316...   \n",
              "38  [[0.43867302, -0.5757887, 0.06837373, 0.884508...   \n",
              "39  [[-0.60317, 0.6339238, 0.64673686, 0.2067721, ...   \n",
              "40  [[-0.4685375, 0.85025126, 0.027359892, 0.54338...   \n",
              "41  [[-0.35874376, 0.39696497, 0.0512689, 0.394965...   \n",
              "\n",
              "                                             cos_sims           max_indices  \\\n",
              "0   [0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...     [6, 13, 8, 2, 10]   \n",
              "1   [0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...  [13, 14, 24, 21, 22]   \n",
              "2   [0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...       [4, 0, 5, 7, 3]   \n",
              "3   [0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...   [16, 1, 10, 22, 18]   \n",
              "4   [0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...  [17, 24, 27, 23, 11]   \n",
              "5   [0.3493, 0.1777, 0.3825, 0.3818, 0.6233, 0.274...      [0, 1, 4, 2, 10]   \n",
              "6   [0.3683, 0.3841, 0.4057, 0.2514, 0.2161, 0.376...     [8, 24, 6, 12, 0]   \n",
              "7   [0.2803, 0.5277, 0.586, 0.4899, 0.2582, 0.3129...       [8, 9, 3, 6, 1]   \n",
              "8   [0.4344, 0.3029, 0.2193, 0.4994, 0.2677, 0.402...     [13, 11, 4, 5, 9]   \n",
              "9   [0.264, 0.1612, 0.2176, 0.334, 0.4749, 0.3157,...     [7, 9, 20, 18, 2]   \n",
              "10  [0.3799, 0.4287, 0.4177, 0.2887, 0.2608, 0.424...       [5, 9, 8, 7, 6]   \n",
              "11  [0.5381, 0.4211, 0.4739, 0.3841, 0.4821, 0.718...    [8, 20, 10, 25, 4]   \n",
              "12  [0.4903, 0.3772, 0.3284, 0.247, 0.3924, 0.2537...     [12, 7, 0, 8, 16]   \n",
              "13  [0.4882, 0.4144, 0.3545, 0.4965, 0.4219, 0.605...   [14, 13, 15, 12, 6]   \n",
              "14  [0.4536, 0.3516, 0.0837, 0.3955, 0.3462, 0.242...     [4, 10, 6, 0, 13]   \n",
              "15  [0.3762, 0.4199, 0.5615, 0.3088, 0.3103, 0.178...   [1, 14, 10, 13, 15]   \n",
              "16  [0.2942, 0.0347, 0.1484, 0.3521, 0.2208, 0.226...     [10, 2, 3, 0, 11]   \n",
              "17  [0.4001, 0.4176, 0.4674, 0.4893, 0.3817, 0.201...   [0, 19, 13, 16, 15]   \n",
              "18  [0.4042, 0.5469, 0.4425, 0.4178, 0.3863, 0.357...      [7, 12, 8, 6, 5]   \n",
              "19  [0.3044, 0.4409, 0.4676, 0.2382, 0.2735, 0.498...   [16, 15, 14, 13, 1]   \n",
              "20  [0.4411, 0.3462, 0.4147, 0.5275, 0.5248, 0.422...  [16, 27, 25, 12, 18]   \n",
              "21  [0.504, 0.3631, 0.3382, 0.5295, 0.5334, 0.4359...  [12, 17, 15, 13, 18]   \n",
              "22  [0.4522, 0.4322, 0.5483, 0.5862, 0.5467, 0.419...     [18, 8, 1, 17, 9]   \n",
              "23  [0.4549, 0.4348, 0.6415, 0.5586, 0.4275, 0.345...     [9, 4, 3, 23, 18]   \n",
              "24  [0.4431, 0.4574, 0.2417, 0.446, 0.319, 0.3933,...  [11, 21, 22, 24, 18]   \n",
              "25  [0.4305, 0.424, 0.4745, 0.49, 0.2258, 0.4631, ...       [0, 4, 2, 5, 6]   \n",
              "26  [0.5215, 0.411, 0.3943, 0.3584, 0.4121, 0.2679...    [1, 18, 4, 14, 15]   \n",
              "27  [0.5351, 0.3642, 0.5143, 0.4508, 0.5693, 0.406...     [2, 20, 7, 5, 24]   \n",
              "28  [0.5029, 0.5383, 0.4751, 0.3751, 0.1729, 0.539...       [2, 7, 6, 4, 9]   \n",
              "29  [0.2942, 0.0347, 0.1484, 0.3521, 0.2208, 0.226...     [10, 2, 3, 0, 11]   \n",
              "30  [0.5505, 0.5235, 0.4628, 0.318, 0.1493, 0.4712...       [0, 5, 4, 7, 8]   \n",
              "31  [0.2241, 0.3055, 0.1869, 0.4872, 0.3614, 0.384...       [0, 3, 8, 7, 5]   \n",
              "32  [0.425, 0.3779, 0.3066, 0.423, 0.4937, 0.3593,...     [1, 8, 10, 2, 11]   \n",
              "33  [0.3428, 0.4169, 0.4036, 0.466, 0.3784, 0.4686...   [18, 25, 15, 2, 28]   \n",
              "34           [0.3594, 0.2066, 0.3973, 0.1688, 0.5011]       [2, 3, 0, 4, 1]   \n",
              "35  [0.4704, 0.3946, 0.3859, 0.3578, 0.6258, 0.251...      [11, 6, 2, 3, 0]   \n",
              "36  [0.3602, 0.5547, 0.3871, 0.3304, 0.3701, 0.624...   [17, 13, 6, 10, 16]   \n",
              "37  [0.4385, 0.2604, 0.5682, 0.2363, 0.4825, 0.457...      [3, 9, 11, 6, 4]   \n",
              "38  [0.4681, 0.4567, 0.1056, 0.4361, 0.5131, 0.484...       [7, 1, 8, 6, 5]   \n",
              "39  [0.4197, 0.3743, 0.2834, 0.1661, 0.6409, 0.532...   [15, 18, 22, 23, 5]   \n",
              "40  [0.3151, 0.462, 0.4276, 0.2333, 0.413, 0.3377,...    [13, 11, 15, 8, 0]   \n",
              "41  [0.4809, 0.4189, 0.3145, 0.3028, 0.5205, 0.435...     [1, 7, 19, 14, 2]   \n",
              "\n",
              "                               contribution_sentences  \\\n",
              "0   [the proposed neural network architecture, whi...   \n",
              "1   [the second mechanism is the dynamic unfolding...   \n",
              "2   [recent work has achieved significant improvem...   \n",
              "3   [this topology can be used for both the encode...   \n",
              "4   [to map the latent representations from differ...   \n",
              "5   [neural machine translation is a rapidly chang...   \n",
              "6   [when the size of a text corpus grows, the fre...   \n",
              "7   [for the other methods, depending on the mecha...   \n",
              "8   [the transition-based algorithm likewise surpa...   \n",
              "9   [this provides, for example, audio generation ...   \n",
              "10  [since the lm embeddings are used to compute t...   \n",
              "11  [using intrinsic evaluations, we show that the...   \n",
              "12  [in particular, each word receives information...   \n",
              "13  [we describe how we compute ls vectors in sect...   \n",
              "14  [the issue of using a chart-based parser is it...   \n",
              "15  [these include sentence-level tasks such as na...   \n",
              "16  [previously, word2vec, which is one of the mos...   \n",
              "17  [this paper addresses the challenging problem ...   \n",
              "18  [our model is generic, requiring no prior know...   \n",
              "19  [we also present the first successful applicat...   \n",
              "20  [we also use a sliding window acting on a subs...   \n",
              "21  [then, it deploys an iterative inference proce...   \n",
              "22  [these enhancements alleviate the problem of l...   \n",
              "23  [they need complicated feature engineering and...   \n",
              "24  [this means that relations of other pairs of e...   \n",
              "25  [many neural network methods have recently bee...   \n",
              "26  [successful relation extraction is the corners...   \n",
              "27  [such information is useful in many other nlp ...   \n",
              "28  [for example, given a sentence with tagged ent...   \n",
              "29  [previously, word2vec, which is one of the mos...   \n",
              "30  [relation extraction aims to find the semantic...   \n",
              "31  [the exponential increase in the volume of sci...   \n",
              "32  [the range of text classification research goe...   \n",
              "33  [therefore, the output from each time step can...   \n",
              "34  [despite their simplicity, they often obtain s...   \n",
              "35  [the goal of our evaluation study is to find a...   \n",
              "36  [our work provides anew perspective on how to ...   \n",
              "37  [jeremy focused on the algorithm development a...   \n",
              "38  [the sentence encoding models are made publicl...   \n",
              "39  [on the other hand, methods that are spatially...   \n",
              "40  [this strategy is demonstrated to exhibit comp...   \n",
              "41  [this task is important as it is widely used i...   \n",
              "\n",
              "                                         contribution  \\\n",
              "0   the proposed neural network architecture, whic...   \n",
              "1   the second mechanism is the dynamic unfolding ...   \n",
              "2   recent work has achieved significant improveme...   \n",
              "3   this topology can be used for both the encoder...   \n",
              "4   to map the latent representations from differe...   \n",
              "5   neural machine translation is a rapidly changi...   \n",
              "6   when the size of a text corpus grows, the freq...   \n",
              "7   for the other methods, depending on the mechan...   \n",
              "8   the transition-based algorithm likewise surpas...   \n",
              "9   this provides, for example, audio generation m...   \n",
              "10  since the lm embeddings are used to compute th...   \n",
              "11  using intrinsic evaluations, we show that the ...   \n",
              "12  in particular, each word receives information ...   \n",
              "13  we describe how we compute ls vectors in secti...   \n",
              "14  the issue of using a chart-based parser is its...   \n",
              "15  these include sentence-level tasks such as nat...   \n",
              "16  previously, word2vec, which is one of the most...   \n",
              "17  this paper addresses the challenging problem o...   \n",
              "18  our model is generic, requiring no prior knowl...   \n",
              "19  we also present the first successful applicati...   \n",
              "20  we also use a sliding window acting on a subse...   \n",
              "21  then, it deploys an iterative inference proces...   \n",
              "22  these enhancements alleviate the problem of lo...   \n",
              "23  they need complicated feature engineering and ...   \n",
              "24  this means that relations of other pairs of en...   \n",
              "25  many neural network methods have recently been...   \n",
              "26  successful relation extraction is the cornerst...   \n",
              "27  such information is useful in many other nlp t...   \n",
              "28  for example, given a sentence with tagged enti...   \n",
              "29  previously, word2vec, which is one of the most...   \n",
              "30  relation extraction aims to find the semantic ...   \n",
              "31  the exponential increase in the volume of scie...   \n",
              "32  the range of text classification research goes...   \n",
              "33  therefore, the output from each time step can ...   \n",
              "34  despite their simplicity, they often obtain st...   \n",
              "35  the goal of our evaluation study is to find an...   \n",
              "36  our work provides anew perspective on how to i...   \n",
              "37  jeremy focused on the algorithm development an...   \n",
              "38  the sentence encoding models are made publicly...   \n",
              "39  on the other hand, methods that are spatially ...   \n",
              "40  this strategy is demonstrated to exhibit compa...   \n",
              "41  this task is important as it is widely used in...   \n",
              "\n",
              "                                 contribution_summary  \n",
              "0    The proposed neural network architecture cons...  \n",
              "1    The bytenet is the instance within this famil...  \n",
              "2    Recent work has achieved significant improvem...  \n",
              "3    nmt models encode the source sequence into co...  \n",
              "4    We propose the weightsharing constraint to th...  \n",
              "5    neural machine translation is a rapidly chang...  \n",
              "6    When the size of a text corpus grows, the fre...  \n",
              "7    The most intuitional method is to randomly se...  \n",
              "8    The transition-based algorithm surpasses the ...  \n",
              "9    The id-cnn consistently outperforms a bidirec...  \n",
              "10   The lm embeddings are used to compute the pro...  \n",
              "11   Using intrinsic evaluations, we show that the...  \n",
              "12   We view the whole sentence as a single state,...  \n",
              "13   We establish anew state-of-the-art f1 score o...  \n",
              "14   The issue of using a chart-based parscher is ...  \n",
              "15   There are two existing strategies for applyin...  \n",
              "16   Word2vec, which is one of the most widely kno...  \n",
              "17   This paper addresses the challenging problem ...  \n",
              "18   This is part of our continuing effort 1 in un...  \n",
              "19   We present the first successful application o...  \n",
              "20   We use a sliding window acting on a subsenten...  \n",
              "21   A novel alternating attention mechanism alter...  \n",
              "22   On end-to-end relation extraction, we improve...  \n",
              "23   Separate framework makes the task easy to dea...  \n",
              "24   The model of strongly relies on the features ...  \n",
              "25   neural network methods have recently been exp...  \n",
              "26   Successful relation extraction is the corners...  \n",
              "27   Joint approaches are feature-based supervised...  \n",
              "28   tagged entity pairs could be powerful hints f...  \n",
              "29   Word2vec, which is one of the most widely kno...  \n",
              "30   The proposed solution is built on top of the ...  \n",
              "31   The exponential increase in the volume of sci...  \n",
              "32   Almost all techniques of text classification ...  \n",
              "33   Lstm models and one-hot cnn strongly outperfo...  \n",
              "34   Text classification is an important task in n...  \n",
              "35   The goal of our evaluation study is to find a...  \n",
              "36   A meta network generates a set of contextsens...  \n",
              "37   While deep learning models have achieved stat...  \n",
              "38   The sentence encoding models are made publicl...  \n",
              "39   Spatially insensitive methods that are spatia...  \n",
              "40   This strategy is demonstrated to exhibit comp...  \n",
              "41   Language has its own linguistic and cultural ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74c4cfcc-9902-4c43-afb4-62b86e7f4752\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>intro</th>\n",
              "      <th>intro_emb</th>\n",
              "      <th>cos_sims</th>\n",
              "      <th>max_indices</th>\n",
              "      <th>contribution_sentences</th>\n",
              "      <th>contribution</th>\n",
              "      <th>contribution_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
              "      <td>in this paper, we propose a novel neural netwo...</td>\n",
              "      <td>[deep neural networks have shown great success...</td>\n",
              "      <td>[[-0.5204625, 0.3894874, 0.6813701, 0.2167664,...</td>\n",
              "      <td>[0.4089, 0.4027, 0.4855, 0.407, 0.4993, 0.3783...</td>\n",
              "      <td>[6, 13, 8, 2, 10]</td>\n",
              "      <td>[the proposed neural network architecture, whi...</td>\n",
              "      <td>the proposed neural network architecture, whic...</td>\n",
              "      <td>The proposed neural network architecture cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Neural Machine Translation in Linear Time</td>\n",
              "      <td>we present a novel neural network for processi...</td>\n",
              "      <td>[in neural language modelling, a neural networ...</td>\n",
              "      <td>[[0.108251475, -0.08667581, 0.55444056, 0.4823...</td>\n",
              "      <td>[0.429, 0.3613, 0.3702, 0.2699, 0.2964, 0.3054...</td>\n",
              "      <td>[13, 14, 24, 21, 22]</td>\n",
              "      <td>[the second mechanism is the dynamic unfolding...</td>\n",
              "      <td>the second mechanism is the dynamic unfolding ...</td>\n",
              "      <td>The bytenet is the instance within this famil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attention Is All You Need</td>\n",
              "      <td>the dominant sequence transduction models are ...</td>\n",
              "      <td>[recurrent neural networks, long short-term me...</td>\n",
              "      <td>[[-0.5715559, 0.25395942, 0.8929722, 0.3264975...</td>\n",
              "      <td>[0.4148, 0.4394, 0.4495, 0.2292, 0.3637, 0.416...</td>\n",
              "      <td>[4, 0, 5, 7, 3]</td>\n",
              "      <td>[recent work has achieved significant improvem...</td>\n",
              "      <td>recent work has achieved significant improveme...</td>\n",
              "      <td>Recent work has achieved significant improvem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deep Recurrent Models with Fast-Forward Connec...</td>\n",
              "      <td>neural machine translation aims at solving mac...</td>\n",
              "      <td>[neural machine translation has attracted a lo...</td>\n",
              "      <td>[[-0.14071748, -0.097277634, 1.2162398, -0.146...</td>\n",
              "      <td>[0.3175, 0.3491, 0.3838, 0.4567, 0.4397, 0.280...</td>\n",
              "      <td>[16, 1, 10, 22, 18]</td>\n",
              "      <td>[this topology can be used for both the encode...</td>\n",
              "      <td>this topology can be used for both the encoder...</td>\n",
              "      <td>nmt models encode the source sequence into co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Unsupervised Neural Machine Translation with W...</td>\n",
              "      <td>unsupervised neural machine translation is a r...</td>\n",
              "      <td>[neural machine translation, directly applying...</td>\n",
              "      <td>[[-0.29525474, 0.02305621, 0.42409566, 0.11174...</td>\n",
              "      <td>[0.3657, 0.4502, 0.4201, 0.4575, 0.5012, 0.079...</td>\n",
              "      <td>[17, 24, 27, 23, 11]</td>\n",
              "      <td>[to map the latent representations from differ...</td>\n",
              "      <td>to map the latent representations from differe...</td>\n",
              "      <td>We propose the weightsharing constraint to th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Tilde's Machine Translation Systems for WMT 2018</td>\n",
              "      <td>the paper describes the development process of...</td>\n",
              "      <td>[neural machine translation is a rapidly chang...</td>\n",
              "      <td>[[-0.13414781, -0.2282693, 1.2828408, -0.17528...</td>\n",
              "      <td>[0.3493, 0.1777, 0.3825, 0.3818, 0.6233, 0.274...</td>\n",
              "      <td>[0, 1, 4, 2, 10]</td>\n",
              "      <td>[neural machine translation is a rapidly chang...</td>\n",
              "      <td>neural machine translation is a rapidly changi...</td>\n",
              "      <td>neural machine translation is a rapidly chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FRAGE: Frequency-Agnostic Word Representation</td>\n",
              "      <td>continuous word representation is a basic buil...</td>\n",
              "      <td>[word embeddings, which are distributed and co...</td>\n",
              "      <td>[[-0.45439413, 0.37135765, 0.23966111, 0.35358...</td>\n",
              "      <td>[0.3683, 0.3841, 0.4057, 0.2514, 0.2161, 0.376...</td>\n",
              "      <td>[8, 24, 6, 12, 0]</td>\n",
              "      <td>[when the size of a text corpus grows, the fre...</td>\n",
              "      <td>when the size of a text corpus grows, the freq...</td>\n",
              "      <td>When the size of a text corpus grows, the fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0,000+ Times Accelerated Robust Subset Selecti...</td>\n",
              "      <td>subset selection from massive data with noised...</td>\n",
              "      <td>[due to the explosive growth of data, subset s...</td>\n",
              "      <td>[[-0.1329963, -0.22868472, 1.4659978, 0.183145...</td>\n",
              "      <td>[0.2803, 0.5277, 0.586, 0.4899, 0.2582, 0.3129...</td>\n",
              "      <td>[8, 9, 3, 6, 1]</td>\n",
              "      <td>[for the other methods, depending on the mecha...</td>\n",
              "      <td>for the other methods, depending on the mechan...</td>\n",
              "      <td>The most intuitional method is to randomly se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Neural Architectures for Named Entity Recognition</td>\n",
              "      <td>state-of-the-art named entity recognition syst...</td>\n",
              "      <td>[named entity recognition is a challenging lea...</td>\n",
              "      <td>[[-0.25237015, 0.22781274, 1.0218633, 0.704382...</td>\n",
              "      <td>[0.4344, 0.3029, 0.2193, 0.4994, 0.2677, 0.402...</td>\n",
              "      <td>[13, 11, 4, 5, 9]</td>\n",
              "      <td>[the transition-based algorithm likewise surpa...</td>\n",
              "      <td>the transition-based algorithm likewise surpas...</td>\n",
              "      <td>The transition-based algorithm surpasses the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Fast and Accurate Entity Recognition with Iter...</td>\n",
              "      <td>today when many practitioners run basic nlp on...</td>\n",
              "      <td>[in order to democratize large-scale nlp and i...</td>\n",
              "      <td>[[-0.5760207, 0.504138, 0.29743108, 0.48354793...</td>\n",
              "      <td>[0.264, 0.1612, 0.2176, 0.334, 0.4749, 0.3157,...</td>\n",
              "      <td>[7, 9, 20, 18, 2]</td>\n",
              "      <td>[this provides, for example, audio generation ...</td>\n",
              "      <td>this provides, for example, audio generation m...</td>\n",
              "      <td>The id-cnn consistently outperforms a bidirec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Semi-supervised sequence tagging with bidirect...</td>\n",
              "      <td>pre-trained word embeddings learned from unlab...</td>\n",
              "      <td>[due to their simplicity and efficacy, pre-tra...</td>\n",
              "      <td>[[-0.29862925, 0.1646118, 0.4163921, 0.2801728...</td>\n",
              "      <td>[0.3799, 0.4287, 0.4177, 0.2887, 0.2608, 0.424...</td>\n",
              "      <td>[5, 9, 8, 7, 6]</td>\n",
              "      <td>[since the lm embeddings are used to compute t...</td>\n",
              "      <td>since the lm embeddings are used to compute th...</td>\n",
              "      <td>The lm embeddings are used to compute the pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Deep contextualized word representations</td>\n",
              "      <td>we introduce anew type of deep contextualized ...</td>\n",
              "      <td>[pre-trained word representations area key com...</td>\n",
              "      <td>[[0.016203806, 0.21462773, 1.0062764, 0.434290...</td>\n",
              "      <td>[0.5381, 0.4211, 0.4739, 0.3841, 0.4821, 0.718...</td>\n",
              "      <td>[8, 20, 10, 25, 4]</td>\n",
              "      <td>[using intrinsic evaluations, we show that the...</td>\n",
              "      <td>using intrinsic evaluations, we show that the ...</td>\n",
              "      <td>Using intrinsic evaluations, we show that the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence-State LSTM for Text Representation</td>\n",
              "      <td>bi-directional lstms area powerful tool for te...</td>\n",
              "      <td>[neural models have become the dominant approa...</td>\n",
              "      <td>[[-0.17486975, -0.41252342, 1.5462731, -0.2084...</td>\n",
              "      <td>[0.4903, 0.3772, 0.3284, 0.247, 0.3924, 0.2537...</td>\n",
              "      <td>[12, 7, 0, 8, 16]</td>\n",
              "      <td>[in particular, each word receives information...</td>\n",
              "      <td>in particular, each word receives information ...</td>\n",
              "      <td>We view the whole sentence as a single state,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Robust Lexical Features for Improved Neural Ne...</td>\n",
              "      <td>neural network approaches to named-entity reco...</td>\n",
              "      <td>[named-entity recognition is the task of ident...</td>\n",
              "      <td>[[-0.027427938, 0.7781579, 0.14958529, 0.33615...</td>\n",
              "      <td>[0.4882, 0.4144, 0.3545, 0.4965, 0.4219, 0.605...</td>\n",
              "      <td>[14, 13, 15, 12, 6]</td>\n",
              "      <td>[we describe how we compute ls vectors in sect...</td>\n",
              "      <td>we describe how we compute ls vectors in secti...</td>\n",
              "      <td>We establish anew state-of-the-art f1 score o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A Neural Transition-based Model for Nested Men...</td>\n",
              "      <td>it is common that entity mentions can contain ...</td>\n",
              "      <td>[there has been an increasing interest in name...</td>\n",
              "      <td>[[0.080848336, 0.33237612, 1.3055669, 0.028802...</td>\n",
              "      <td>[0.4536, 0.3516, 0.0837, 0.3955, 0.3462, 0.242...</td>\n",
              "      <td>[4, 10, 6, 0, 13]</td>\n",
              "      <td>[the issue of using a chart-based parser is it...</td>\n",
              "      <td>the issue of using a chart-based parser is its...</td>\n",
              "      <td>The issue of using a chart-based parscher is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>BERT: Pre-training of Deep Bidirectional Trans...</td>\n",
              "      <td>we introduce anew language representation mode...</td>\n",
              "      <td>[language model pre-training has been shown to...</td>\n",
              "      <td>[[-0.28008252, -0.18042819, 0.6790624, -0.0071...</td>\n",
              "      <td>[0.3762, 0.4199, 0.5615, 0.3088, 0.3103, 0.178...</td>\n",
              "      <td>[1, 14, 10, 13, 15]</td>\n",
              "      <td>[these include sentence-level tasks such as na...</td>\n",
              "      <td>these include sentence-level tasks such as nat...</td>\n",
              "      <td>There are two existing strategies for applyin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Data and text mining BioBERT: a pre-trained bi...</td>\n",
              "      <td>motivation: biomedical text mining is becoming...</td>\n",
              "      <td>[the volume of biomedical literature continues...</td>\n",
              "      <td>[[0.7987201, -0.15887147, 1.7703805, -0.278009...</td>\n",
              "      <td>[0.2942, 0.0347, 0.1484, 0.3521, 0.2208, 0.226...</td>\n",
              "      <td>[10, 2, 3, 0, 11]</td>\n",
              "      <td>[previously, word2vec, which is one of the mos...</td>\n",
              "      <td>previously, word2vec, which is one of the most...</td>\n",
              "      <td>Word2vec, which is one of the most widely kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Open Question Answering with Weakly Supervised...</td>\n",
              "      <td>building computers able to answer questions on...</td>\n",
              "      <td>[this paper addresses the challenging problem ...</td>\n",
              "      <td>[[-0.25996676, 0.6575827, 0.79837936, 0.637119...</td>\n",
              "      <td>[0.4001, 0.4176, 0.4674, 0.4893, 0.3817, 0.201...</td>\n",
              "      <td>[0, 19, 13, 16, 15]</td>\n",
              "      <td>[this paper addresses the challenging problem ...</td>\n",
              "      <td>this paper addresses the challenging problem o...</td>\n",
              "      <td>This paper addresses the challenging problem ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Convolutional Neural Network Architectures for...</td>\n",
              "      <td>semantic matching is of central importance to ...</td>\n",
              "      <td>[matching two potentially heterogenous languag...</td>\n",
              "      <td>[[-0.2356596, 0.29604667, 0.17470802, 0.207097...</td>\n",
              "      <td>[0.4042, 0.5469, 0.4425, 0.4178, 0.3863, 0.357...</td>\n",
              "      <td>[7, 12, 8, 6, 5]</td>\n",
              "      <td>[our model is generic, requiring no prior know...</td>\n",
              "      <td>our model is generic, requiring no prior knowl...</td>\n",
              "      <td>This is part of our continuing effort 1 in un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Large-scale Simple Question Answering with Mem...</td>\n",
              "      <td>training large-scale question answering system...</td>\n",
              "      <td>[open-domain question answering systems aim at...</td>\n",
              "      <td>[[-0.15790537, 0.49199095, 0.26630324, 0.39525...</td>\n",
              "      <td>[0.3044, 0.4409, 0.4676, 0.2382, 0.2735, 0.498...</td>\n",
              "      <td>[16, 15, 14, 13, 1]</td>\n",
              "      <td>[we also present the first successful applicat...</td>\n",
              "      <td>we also present the first successful applicati...</td>\n",
              "      <td>We present the first successful application o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>A Parallel-Hierarchical Model for Machine Comp...</td>\n",
              "      <td>understanding unstructured text is a major goa...</td>\n",
              "      <td>[humans learn in a variety of ways-by communic...</td>\n",
              "      <td>[[-0.2681135, 0.51422447, 1.1493917, 0.6535939...</td>\n",
              "      <td>[0.4411, 0.3462, 0.4147, 0.5275, 0.5248, 0.422...</td>\n",
              "      <td>[16, 27, 25, 12, 18]</td>\n",
              "      <td>[we also use a sliding window acting on a subs...</td>\n",
              "      <td>we also use a sliding window acting on a subse...</td>\n",
              "      <td>We use a sliding window acting on a subsenten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Iterative Alternating Neural Attention for Mac...</td>\n",
              "      <td>we propose a novel neural attention architectu...</td>\n",
              "      <td>[recently, the idea of training machine compre...</td>\n",
              "      <td>[[-0.61436677, -0.12127957, 1.5850064, 0.62324...</td>\n",
              "      <td>[0.504, 0.3631, 0.3382, 0.5295, 0.5334, 0.4359...</td>\n",
              "      <td>[12, 17, 15, 13, 18]</td>\n",
              "      <td>[then, it deploys an iterative inference proce...</td>\n",
              "      <td>then, it deploys an iterative inference proces...</td>\n",
              "      <td>A novel alternating attention mechanism alter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>End-to-End Relation Extraction using LSTMs on ...</td>\n",
              "      <td>we present a novel end-to-end neural model to ...</td>\n",
              "      <td>[extracting semantic relations between entitie...</td>\n",
              "      <td>[[-0.6867979, 0.5289896, 1.0703982, 0.15692762...</td>\n",
              "      <td>[0.4522, 0.4322, 0.5483, 0.5862, 0.5467, 0.419...</td>\n",
              "      <td>[18, 8, 1, 17, 9]</td>\n",
              "      <td>[these enhancements alleviate the problem of l...</td>\n",
              "      <td>these enhancements alleviate the problem of lo...</td>\n",
              "      <td>On end-to-end relation extraction, we improve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Joint Extraction of Entities and Relations Bas...</td>\n",
              "      <td>joint extraction of entities and relations is ...</td>\n",
              "      <td>[joint extraction of entities and relations is...</td>\n",
              "      <td>[[-0.415223, 1.097821, 0.59927785, 0.38558003,...</td>\n",
              "      <td>[0.4549, 0.4348, 0.6415, 0.5586, 0.4275, 0.345...</td>\n",
              "      <td>[9, 4, 3, 23, 18]</td>\n",
              "      <td>[they need complicated feature engineering and...</td>\n",
              "      <td>they need complicated feature engineering and ...</td>\n",
              "      <td>Separate framework makes the task easy to dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Joint entity recognition and relation extracti...</td>\n",
              "      <td>state-of-the-art models for joint entity recog...</td>\n",
              "      <td>[the goal of the entity recognition and relati...</td>\n",
              "      <td>[[-0.41306046, 1.675093, 0.2402155, 0.35095933...</td>\n",
              "      <td>[0.4431, 0.4574, 0.2417, 0.446, 0.319, 0.3933,...</td>\n",
              "      <td>[11, 21, 22, 24, 18]</td>\n",
              "      <td>[this means that relations of other pairs of e...</td>\n",
              "      <td>this means that relations of other pairs of en...</td>\n",
              "      <td>The model of strongly relies on the features ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Adversarial training for multi-context joint e...</td>\n",
              "      <td>adversarial training is a regularization metho...</td>\n",
              "      <td>[many neural network methods have recently bee...</td>\n",
              "      <td>[[-0.10987496, 0.09705745, 0.6809278, 0.286776...</td>\n",
              "      <td>[0.4305, 0.424, 0.4745, 0.49, 0.2258, 0.4631, ...</td>\n",
              "      <td>[0, 4, 2, 5, 6]</td>\n",
              "      <td>[many neural network methods have recently bee...</td>\n",
              "      <td>many neural network methods have recently been...</td>\n",
              "      <td>neural network methods have recently been exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Graph Convolution over Pruned Dependency Trees...</td>\n",
              "      <td>dependency trees help relation extraction mode...</td>\n",
              "      <td>[relation extraction involves discerning wheth...</td>\n",
              "      <td>[[-0.17918232, 0.25339183, 0.27279842, 0.33350...</td>\n",
              "      <td>[0.5215, 0.411, 0.3943, 0.3584, 0.4121, 0.2679...</td>\n",
              "      <td>[1, 18, 4, 14, 15]</td>\n",
              "      <td>[successful relation extraction is the corners...</td>\n",
              "      <td>successful relation extraction is the cornerst...</td>\n",
              "      <td>Successful relation extraction is the corners...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>End-to-end neural relation extraction using de...</td>\n",
              "      <td>we propose a neural network model for joint ex...</td>\n",
              "      <td>[extracting entities and their semantic relati...</td>\n",
              "      <td>[[-0.33283246, 0.36472216, 0.9390662, 0.642776...</td>\n",
              "      <td>[0.5351, 0.3642, 0.5143, 0.4508, 0.5693, 0.406...</td>\n",
              "      <td>[2, 20, 7, 5, 24]</td>\n",
              "      <td>[such information is useful in many other nlp ...</td>\n",
              "      <td>such information is useful in many other nlp t...</td>\n",
              "      <td>Joint approaches are feature-based supervised...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Semantic Relation Classification via Bidirecti...</td>\n",
              "      <td>classifying semantic relations between entity ...</td>\n",
              "      <td>[classifying semantic relations between entity...</td>\n",
              "      <td>[[-0.608256, 0.55602336, 0.6793852, 0.5575708,...</td>\n",
              "      <td>[0.5029, 0.5383, 0.4751, 0.3751, 0.1729, 0.539...</td>\n",
              "      <td>[2, 7, 6, 4, 9]</td>\n",
              "      <td>[for example, given a sentence with tagged ent...</td>\n",
              "      <td>for example, given a sentence with tagged enti...</td>\n",
              "      <td>tagged entity pairs could be powerful hints f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Data and text mining BioBERT: a pre-trained bi...</td>\n",
              "      <td>motivation: biomedical text mining is becoming...</td>\n",
              "      <td>[the volume of biomedical literature continues...</td>\n",
              "      <td>[[0.7987201, -0.15887147, 1.7703805, -0.278009...</td>\n",
              "      <td>[0.2942, 0.0347, 0.1484, 0.3521, 0.2208, 0.226...</td>\n",
              "      <td>[10, 2, 3, 0, 11]</td>\n",
              "      <td>[previously, word2vec, which is one of the mos...</td>\n",
              "      <td>previously, word2vec, which is one of the most...</td>\n",
              "      <td>Word2vec, which is one of the most widely kno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Extracting Multiple-Relations in One-Pass with...</td>\n",
              "      <td>the state-of-the-art solutions for extracting ...</td>\n",
              "      <td>[relation extraction aims to find the semantic...</td>\n",
              "      <td>[[-0.21298881, 0.6873293, 0.68065774, 0.259553...</td>\n",
              "      <td>[0.5505, 0.5235, 0.4628, 0.318, 0.1493, 0.4712...</td>\n",
              "      <td>[0, 5, 4, 7, 8]</td>\n",
              "      <td>[relation extraction aims to find the semantic...</td>\n",
              "      <td>relation extraction aims to find the semantic ...</td>\n",
              "      <td>The proposed solution is built on top of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>SCIBERT: A Pretrained Language Model for Scien...</td>\n",
              "      <td>obtaining large-scale annotated data for nlp t...</td>\n",
              "      <td>[the exponential increase in the volume of sci...</td>\n",
              "      <td>[[-0.35356942, -0.083761044, 0.94317627, -0.08...</td>\n",
              "      <td>[0.2241, 0.3055, 0.1869, 0.4872, 0.3614, 0.384...</td>\n",
              "      <td>[0, 3, 8, 7, 5]</td>\n",
              "      <td>[the exponential increase in the volume of sci...</td>\n",
              "      <td>the exponential increase in the volume of scie...</td>\n",
              "      <td>The exponential increase in the volume of sci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Character-level Convolutional Networks for Tex...</td>\n",
              "      <td>this article offers an empirical exploration o...</td>\n",
              "      <td>[text classification is a classic topic for na...</td>\n",
              "      <td>[[-0.26952654, 0.57736915, 0.43923575, 0.63989...</td>\n",
              "      <td>[0.425, 0.3779, 0.3066, 0.423, 0.4937, 0.3593,...</td>\n",
              "      <td>[1, 8, 10, 2, 11]</td>\n",
              "      <td>[the range of text classification research goe...</td>\n",
              "      <td>the range of text classification research goes...</td>\n",
              "      <td>Almost all techniques of text classification ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Supervised and Semi-Supervised Text Categoriza...</td>\n",
              "      <td>one-hot cnn has been shown to be effective for...</td>\n",
              "      <td>[text categorization is the task of assigning ...</td>\n",
              "      <td>[[-0.333069, 0.50793964, 0.14468037, 0.3841369...</td>\n",
              "      <td>[0.3428, 0.4169, 0.4036, 0.466, 0.3784, 0.4686...</td>\n",
              "      <td>[18, 25, 15, 2, 28]</td>\n",
              "      <td>[therefore, the output from each time step can...</td>\n",
              "      <td>therefore, the output from each time step can ...</td>\n",
              "      <td>Lstm models and one-hot cnn strongly outperfo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Bag of Tricks for Efficient Text Classification</td>\n",
              "      <td>this paper explores a simple and efficient bas...</td>\n",
              "      <td>[text classification is an important task in n...</td>\n",
              "      <td>[[-0.41828865, 0.1735431, 1.5629678, 0.0858151...</td>\n",
              "      <td>[0.3594, 0.2066, 0.3973, 0.1688, 0.5011]</td>\n",
              "      <td>[2, 3, 0, 4, 1]</td>\n",
              "      <td>[despite their simplicity, they often obtain s...</td>\n",
              "      <td>despite their simplicity, they often obtain st...</td>\n",
              "      <td>Text classification is an important task in n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>On the Role of Text Preprocessing in Neural Ne...</td>\n",
              "      <td>text preprocessing is often the first step in ...</td>\n",
              "      <td>[words are often considered as the basic const...</td>\n",
              "      <td>[[-0.54336274, 1.0743241, -0.1217025, -0.10105...</td>\n",
              "      <td>[0.4704, 0.3946, 0.3859, 0.3578, 0.6258, 0.251...</td>\n",
              "      <td>[11, 6, 2, 3, 0]</td>\n",
              "      <td>[the goal of our evaluation study is to find a...</td>\n",
              "      <td>the goal of our evaluation study is to find an...</td>\n",
              "      <td>The goal of our evaluation study is to find a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Learning Context-Sensitive Convolutional Filte...</td>\n",
              "      <td>convolutional neural networks have recently em...</td>\n",
              "      <td>[in the last few years, convolutional neural n...</td>\n",
              "      <td>[[-0.33753395, 0.052655704, 0.9955412, -0.0359...</td>\n",
              "      <td>[0.3602, 0.5547, 0.3871, 0.3304, 0.3701, 0.624...</td>\n",
              "      <td>[17, 13, 6, 10, 16]</td>\n",
              "      <td>[our work provides anew perspective on how to ...</td>\n",
              "      <td>our work provides anew perspective on how to i...</td>\n",
              "      <td>A meta network generates a set of contextsens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Universal Language Model Fine-tuning for Text ...</td>\n",
              "      <td>inductive transfer learning has greatly impact...</td>\n",
              "      <td>[inductive transfer learning has had a large i...</td>\n",
              "      <td>[[-0.13765128, -0.15379387, 0.95918, 0.3047316...</td>\n",
              "      <td>[0.4385, 0.2604, 0.5682, 0.2363, 0.4825, 0.457...</td>\n",
              "      <td>[3, 9, 11, 6, 4]</td>\n",
              "      <td>[jeremy focused on the algorithm development a...</td>\n",
              "      <td>jeremy focused on the algorithm development an...</td>\n",
              "      <td>While deep learning models have achieved stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Universal Sentence Encoder</td>\n",
              "      <td>we present models for encoding sentences into ...</td>\n",
              "      <td>[limited amounts of training data are availabl...</td>\n",
              "      <td>[[0.43867302, -0.5757887, 0.06837373, 0.884508...</td>\n",
              "      <td>[0.4681, 0.4567, 0.1056, 0.4361, 0.5131, 0.484...</td>\n",
              "      <td>[7, 1, 8, 6, 5]</td>\n",
              "      <td>[the sentence encoding models are made publicl...</td>\n",
              "      <td>the sentence encoding models are made publicly...</td>\n",
              "      <td>The sentence encoding models are made publicl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Investigating Capsule Networks with Dynamic Ro...</td>\n",
              "      <td>in this study, we explore capsule networks wit...</td>\n",
              "      <td>[modeling articles or sentences computationall...</td>\n",
              "      <td>[[-0.60317, 0.6339238, 0.64673686, 0.2067721, ...</td>\n",
              "      <td>[0.4197, 0.3743, 0.2834, 0.1661, 0.6409, 0.532...</td>\n",
              "      <td>[15, 18, 22, 23, 5]</td>\n",
              "      <td>[on the other hand, methods that are spatially...</td>\n",
              "      <td>on the other hand, methods that are spatially ...</td>\n",
              "      <td>Spatially insensitive methods that are spatia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Baseline Needs More Love: On Simple Word-Embed...</td>\n",
              "      <td>many deep learning architectures have been pro...</td>\n",
              "      <td>[word embeddings, learned from massive unstruc...</td>\n",
              "      <td>[[-0.4685375, 0.85025126, 0.027359892, 0.54338...</td>\n",
              "      <td>[0.3151, 0.462, 0.4276, 0.2333, 0.413, 0.3377,...</td>\n",
              "      <td>[13, 11, 15, 8, 0]</td>\n",
              "      <td>[this strategy is demonstrated to exhibit comp...</td>\n",
              "      <td>this strategy is demonstrated to exhibit compa...</td>\n",
              "      <td>This strategy is demonstrated to exhibit comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Translations as Additional Contexts for Senten...</td>\n",
              "      <td>in sentence classification tasks, additional c...</td>\n",
              "      <td>[one of the primary tasks in natural language ...</td>\n",
              "      <td>[[-0.35874376, 0.39696497, 0.0512689, 0.394965...</td>\n",
              "      <td>[0.4809, 0.4189, 0.3145, 0.3028, 0.5205, 0.435...</td>\n",
              "      <td>[1, 7, 19, 14, 2]</td>\n",
              "      <td>[this task is important as it is widely used i...</td>\n",
              "      <td>this task is important as it is widely used in...</td>\n",
              "      <td>Language has its own linguistic and cultural ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74c4cfcc-9902-4c43-afb4-62b86e7f4752')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74c4cfcc-9902-4c43-afb4-62b86e7f4752 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74c4cfcc-9902-4c43-afb4-62b86e7f4752');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWCV--3K3LLT",
        "outputId": "7c4a4c98-1b49-4ad0-9e43-f9cc1a4b4cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "rouge = Rouge()\n",
        "def get_rouge_score(text, reference):\n",
        "    return rouge.get_scores(text, reference)\n"
      ],
      "metadata": {
        "id": "UG5ohc3N3xl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['rouge_scores'] = data.apply(lambda x: get_rouge_score(x['contribution_summary'], x['abstract']), axis=1)"
      ],
      "metadata": {
        "id": "HvVdsqLg4CYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1QufeFk4tBI",
        "outputId": "1c049100-2137-4585-8eb1-952899bf5fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.7/dist-packages (0.3.11)\n",
            "Requirement already satisfied: transformers>=3.0.0numpy in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.19.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert_score) (21.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.64.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert_score) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (4.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert_score) (3.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mWWot3ak4uBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refs = ['The dog bit the guy.']\n",
        "\n",
        "hyps = ['The dog bit the man.']\n",
        "\n",
        "P, R, F1 = scorer.score(hyps, refs)\n",
        "\n",
        "print(F1.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Zfh-AR5Nez",
        "outputId": "7222722b-523f-4f46-d269-fbe5b3fae30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9603)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bertscore(text, reference):\n",
        "    P, R, F1 = scorer.score(hyps, refs)\n",
        "    return {'precision': P,\n",
        "            'recall': R,\n",
        "            'f1': F1}"
      ],
      "metadata": {
        "id": "YDW_5QWs6vXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['bertscore'] = data.progress_apply(lambda x: get_bertscore([x['contribution_summary']], [x['abstract']]), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "352f4e98926f4280b923b6d03bb7772d",
            "63e0903899674ecc8c3f71ad01f3a51f",
            "fc3dc516bd4b4fcea75cafaea76450c2",
            "f4d1001e08a24c1aa21583c28a30da74",
            "a3f32759002b4fc0b00ccb75a7d47b9f",
            "76f516217438434485e06dd711dd0059",
            "c909b8183ef749808fb0e8bdecc6477b",
            "f0082c0964154c0ca1434ea3f9e17d5b",
            "b4cb255f91d8433a81b67760e38bd5c7",
            "ce2780cbb325486bb3faca33cdc98a8f",
            "13f04029d74d4026851f88e77be9b3ba"
          ]
        },
        "id": "VOa0MXan7HB3",
        "outputId": "f774dfe9-f7e2-48f8-8d71-d2965449782a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/42 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "352f4e98926f4280b923b6d03bb7772d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = data[['contribution', 'contribution_summary', 'rouge_scores', 'bertscore']]\n",
        "final_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wHaRqXsY7Pc9",
        "outputId": "fc6d030e-965d-4b89-da4f-67c8ff76ca8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        contribution  \\\n",
              "0  the proposed neural network architecture, whic...   \n",
              "1  the second mechanism is the dynamic unfolding ...   \n",
              "2  recent work has achieved significant improveme...   \n",
              "3  this topology can be used for both the encoder...   \n",
              "4  to map the latent representations from differe...   \n",
              "\n",
              "                                contribution_summary  \\\n",
              "0   The proposed neural network architecture cons...   \n",
              "1   The bytenet is the instance within this famil...   \n",
              "2   Recent work has achieved significant improvem...   \n",
              "3   nmt models encode the source sequence into co...   \n",
              "4   We propose the weightsharing constraint to th...   \n",
              "\n",
              "                                        rouge_scores  \\\n",
              "0  [{'rouge-1': {'r': 0.4473684210526316, 'p': 0....   \n",
              "1  [{'rouge-1': {'r': 0.28695652173913044, 'p': 0...   \n",
              "2  [{'rouge-1': {'r': 0.13636363636363635, 'p': 0...   \n",
              "3  [{'rouge-1': {'r': 0.288, 'p': 0.5538461538461...   \n",
              "4  [{'rouge-1': {'r': 0.24, 'p': 0.36363636363636...   \n",
              "\n",
              "                                           bertscore  \n",
              "0  {'precision': [tensor(0.9603)], 'recall': [ten...  \n",
              "1  {'precision': [tensor(0.9603)], 'recall': [ten...  \n",
              "2  {'precision': [tensor(0.9603)], 'recall': [ten...  \n",
              "3  {'precision': [tensor(0.9603)], 'recall': [ten...  \n",
              "4  {'precision': [tensor(0.9603)], 'recall': [ten...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d8632d3-346a-426c-8bfe-9509948af964\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contribution</th>\n",
              "      <th>contribution_summary</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>bertscore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the proposed neural network architecture, whic...</td>\n",
              "      <td>The proposed neural network architecture cons...</td>\n",
              "      <td>[{'rouge-1': {'r': 0.4473684210526316, 'p': 0....</td>\n",
              "      <td>{'precision': [tensor(0.9603)], 'recall': [ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the second mechanism is the dynamic unfolding ...</td>\n",
              "      <td>The bytenet is the instance within this famil...</td>\n",
              "      <td>[{'rouge-1': {'r': 0.28695652173913044, 'p': 0...</td>\n",
              "      <td>{'precision': [tensor(0.9603)], 'recall': [ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recent work has achieved significant improveme...</td>\n",
              "      <td>Recent work has achieved significant improvem...</td>\n",
              "      <td>[{'rouge-1': {'r': 0.13636363636363635, 'p': 0...</td>\n",
              "      <td>{'precision': [tensor(0.9603)], 'recall': [ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this topology can be used for both the encoder...</td>\n",
              "      <td>nmt models encode the source sequence into co...</td>\n",
              "      <td>[{'rouge-1': {'r': 0.288, 'p': 0.5538461538461...</td>\n",
              "      <td>{'precision': [tensor(0.9603)], 'recall': [ten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to map the latent representations from differe...</td>\n",
              "      <td>We propose the weightsharing constraint to th...</td>\n",
              "      <td>[{'rouge-1': {'r': 0.24, 'p': 0.36363636363636...</td>\n",
              "      <td>{'precision': [tensor(0.9603)], 'recall': [ten...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d8632d3-346a-426c-8bfe-9509948af964')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d8632d3-346a-426c-8bfe-9509948af964 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d8632d3-346a-426c-8bfe-9509948af964');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('final_answer.csv', index=False)"
      ],
      "metadata": {
        "id": "a1Ihr5Wv7UTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "onjaybni74UR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Passage Retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae0d8d64039d4b31b7e6729233a63a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45f3a0280f1e45e888588f3126c737d8",
              "IPY_MODEL_4fcd0fa8b881452d98c2780b9e563cca",
              "IPY_MODEL_ba56cdb2b0f246cdbb006fa14b0df0c8"
            ],
            "layout": "IPY_MODEL_8714c835e9cc401794e6887a0e5d4367"
          }
        },
        "45f3a0280f1e45e888588f3126c737d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070fbb0cec0641ccaccf7fd490f2faa6",
            "placeholder": "​",
            "style": "IPY_MODEL_17da8de2be1f417db23ebfdca6df159e",
            "value": ""
          }
        },
        "4fcd0fa8b881452d98c2780b9e563cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ea0c46b53b48038e3e5244614586fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5afc893bfd14acdbf26036b5977bbd0",
            "value": 1
          }
        },
        "ba56cdb2b0f246cdbb006fa14b0df0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5344f719298441f5bf8e8c68734e31c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f2d2d5b9d13942419be175198474bdbf",
            "value": " 156/? [00:00&lt;00:00,  6.71it/s]"
          }
        },
        "8714c835e9cc401794e6887a0e5d4367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070fbb0cec0641ccaccf7fd490f2faa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17da8de2be1f417db23ebfdca6df159e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ea0c46b53b48038e3e5244614586fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d5afc893bfd14acdbf26036b5977bbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5344f719298441f5bf8e8c68734e31c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d2d5b9d13942419be175198474bdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94001c34152040af88ccd7cbcdf62e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b790149cf8248c1ab6d487697ef7fbc",
              "IPY_MODEL_1e17656eb11c4884a1faf18a7ddb9e18",
              "IPY_MODEL_bc9e561813be44ce8e202ee5238b3877"
            ],
            "layout": "IPY_MODEL_18aed4e0406644db9f605fa9f8141c4e"
          }
        },
        "7b790149cf8248c1ab6d487697ef7fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7192c1b6f78e42abaad7190d67625ec2",
            "placeholder": "​",
            "style": "IPY_MODEL_32155cd7b9c24134aa847beeafc21ccc",
            "value": "100%"
          }
        },
        "1e17656eb11c4884a1faf18a7ddb9e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9696495e76144e8b94fcbda0ab77dc6",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac4027786a274edcba0fdc9d0070483f",
            "value": 42
          }
        },
        "bc9e561813be44ce8e202ee5238b3877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a47878c80f4639a7dccd818865bca4",
            "placeholder": "​",
            "style": "IPY_MODEL_af69c17f03d240e99f8e8b69f711d708",
            "value": " 42/42 [06:54&lt;00:00,  9.68s/it]"
          }
        },
        "18aed4e0406644db9f605fa9f8141c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7192c1b6f78e42abaad7190d67625ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32155cd7b9c24134aa847beeafc21ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9696495e76144e8b94fcbda0ab77dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4027786a274edcba0fdc9d0070483f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31a47878c80f4639a7dccd818865bca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af69c17f03d240e99f8e8b69f711d708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "352f4e98926f4280b923b6d03bb7772d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e0903899674ecc8c3f71ad01f3a51f",
              "IPY_MODEL_fc3dc516bd4b4fcea75cafaea76450c2",
              "IPY_MODEL_f4d1001e08a24c1aa21583c28a30da74"
            ],
            "layout": "IPY_MODEL_a3f32759002b4fc0b00ccb75a7d47b9f"
          }
        },
        "63e0903899674ecc8c3f71ad01f3a51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f516217438434485e06dd711dd0059",
            "placeholder": "​",
            "style": "IPY_MODEL_c909b8183ef749808fb0e8bdecc6477b",
            "value": "100%"
          }
        },
        "fc3dc516bd4b4fcea75cafaea76450c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0082c0964154c0ca1434ea3f9e17d5b",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4cb255f91d8433a81b67760e38bd5c7",
            "value": 42
          }
        },
        "f4d1001e08a24c1aa21583c28a30da74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2780cbb325486bb3faca33cdc98a8f",
            "placeholder": "​",
            "style": "IPY_MODEL_13f04029d74d4026851f88e77be9b3ba",
            "value": " 42/42 [00:01&lt;00:00, 35.62it/s]"
          }
        },
        "a3f32759002b4fc0b00ccb75a7d47b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f516217438434485e06dd711dd0059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c909b8183ef749808fb0e8bdecc6477b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0082c0964154c0ca1434ea3f9e17d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4cb255f91d8433a81b67760e38bd5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce2780cbb325486bb3faca33cdc98a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f04029d74d4026851f88e77be9b3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}